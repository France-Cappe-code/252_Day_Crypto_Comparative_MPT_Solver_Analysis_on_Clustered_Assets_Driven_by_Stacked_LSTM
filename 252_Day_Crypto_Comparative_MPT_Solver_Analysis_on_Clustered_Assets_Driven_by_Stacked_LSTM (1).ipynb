{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Project Description**\n",
        "\n",
        "This notebook implements a multi-stage quantitative finance model designed not to achieve maximal portfolio performance, but rather to **compare and contrast the simultaneous behavior of three fundamental portfolio construction methodologies**:\n",
        "\n",
        "\n",
        "1.  **MVOR (Mean-Variance Optimized Portfolio):** Maximizing the Sharpe Ratio based on Deep Learning-predicted returns.\n",
        "\n",
        "\n",
        "2.  **GMV (Global Minimum Volatility Portfolio):** Minimizing portfolio risk regardless of returns.\n",
        "\n",
        "\n",
        "3.  **ERC (Equal Risk Contribution Portfolio):** Distributing risk equally among the assets.\n",
        "\n",
        "The core objective is to explore the differences in asset allocation dictated by these classic strategies when fed the same set of predictions and risk data.\n",
        "\n",
        "## **Key Methodological Choices & Research Question**\n",
        "\n",
        "### 1. **Advanced Input Generation**\n",
        "\n",
        "* **Asset Universe:** A basket of 18 major cryptocurrencies (e.g., BTC-USD, ETH-USD, SOL-USD).\n",
        "\n",
        "* **Feature Engineering:** Technical indicators (RSI, MACD, Bollinger Bands, etc.) are computed using the `ta` library to enrich the feature set.\n",
        "\n",
        "* **Deep Learning Prediction:** A **Stacked LSTM (Long Short-Term Memory) network** is trained on historical price data and technical indicators to forecast the one-period-ahead expected returns ($\\mu$) for *all assets simultaneously*.\n",
        "\n",
        "* **Risk Filtering:** K-Means Clustering on historical volatility is used to select a \"**low-risk**\" subset of cryptocurrencies for the final optimization step.\n",
        "\n",
        "### 2. **The Simulation Premise**: Cryptos as Stocks\n",
        "\n",
        "A central experimental assumption of this project is to treat the 24/7 cryptocurrency market **as if it were a traditional stock market**.\n",
        "\n",
        "* **Risk Annualization:** The covariance matrix and volatility are annualized using a **252-day factor** (the approximate number of trading days in a year for equity markets), **rather than** the 365-day factor typical for 24/7 markets.\n",
        "\n",
        "This deliberate choice directly addresses the **following research question**:\n",
        "\n",
        "> **What are the portfolio allocation results, risk metrics, and strategy divergences if I treat a universe of cryptocurrencies as if they were normal stocks?**\n",
        "\n",
        "**WARNING**:\n",
        "\n",
        "This notebook is not a financial advisor."
      ],
      "metadata": {
        "id": "CDcr_SF_7kS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc11pE_09yCW",
        "outputId": "a4d6178c-2f49-466c-fa5b-9d6dc9a8fdb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=b4a68e7b7e02d4cc4da2a27381689cd98c0ef61aa45541da9ff2fafbb30f3a48\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/a1/5f/c6b85a7d9452057be4ce68a8e45d77ba34234a6d46581777c6\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import ta\n",
        "from scipy.optimize import minimize\n",
        "import datetime as dt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input"
      ],
      "metadata": {
        "id": "rM5t0PBd4LaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "MAX_WEIGHT_PER_CRYPTO = 0.15\n",
        "MIN_WEIGHT_PER_CRYPTO = 0.01\n",
        "MIN_CRYPTO_IN_PORTFOLIO = 8\n",
        "\n",
        "RISK_FREE_RATE = 0.02\n",
        "\n",
        "\n",
        "LOOKBACK = 60\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "start_date = \"2020-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "\n",
        "\n",
        "CRYPTO_TICKERS = [\n",
        "    'BTC-USD',\n",
        "    'ETH-USD',\n",
        "    'BNB-USD',\n",
        "    'SOL-USD',\n",
        "    'XRP-USD',\n",
        "    'ADA-USD',\n",
        "    'AVAX-USD',\n",
        "    'DOGE-USD',\n",
        "    'DOT-USD',\n",
        "    'TRX-USD',\n",
        "    'LINK-USD',\n",
        "    'MATIC-USD',\n",
        "    'LTC-USD',\n",
        "    'BCH-USD',\n",
        "    'ATOM-USD',\n",
        "    'UNI-USD',\n",
        "    'XLM-USD',\n",
        "    'ETC-USD',\n",
        "]\n",
        "\n",
        "ALL_TICKERS = CRYPTO_TICKERS\n",
        "\n",
        "\n",
        "\n",
        "def download_crypto_data(tickers, start_date, end_date):\n",
        "\n",
        "    print(f\"Downloading data for {len(tickers)} cryptocurrencies...\")\n",
        "\n",
        "    all_data = {}\n",
        "    successful_tickers = []\n",
        "\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            data = yf.download(ticker, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
        "            if data.empty:\n",
        "                print(f\"    No data for {ticker}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "            if not all(col in data.columns for col in ['Open', 'High', 'Low', 'Close', 'Volume']):\n",
        "                print(f\"    Missing required columns for {ticker}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "            if len(data) < 100:\n",
        "                print(f\"    Insufficient data points for {ticker}\")\n",
        "                continue\n",
        "\n",
        "            all_data[ticker] = data\n",
        "            successful_tickers.append(ticker)\n",
        "            print(f\"    Successfully downloaded {ticker}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error downloading {ticker}: {str(e)}\")\n",
        "\n",
        "    print(f\"Successfully downloaded {len(successful_tickers)} out of {len(tickers)} cryptocurrencies\")\n",
        "    return all_data, successful_tickers\n",
        "\n",
        "def compute_technical_indicators_single(data_df, ticker):\n",
        "\n",
        "    try:\n",
        "\n",
        "        close_prices = data_df['Close'].squeeze()\n",
        "        high_prices = data_df['High'].squeeze()\n",
        "        low_prices = data_df['Low'].squeeze()\n",
        "        open_prices = data_df['Open'].squeeze()\n",
        "        volume = data_df['Volume'].squeeze()\n",
        "\n",
        "        indicators = {}\n",
        "\n",
        "\n",
        "        indicators['RSI'] = ta.momentum.RSIIndicator(close=close_prices, window=14).rsi()\n",
        "\n",
        "\n",
        "        macd = ta.trend.MACD(close=close_prices)\n",
        "        indicators['MACD'] = macd.macd()\n",
        "        indicators['MACD_Signal'] = macd.macd_signal()\n",
        "        indicators['MACD_Histogram'] = macd.macd_diff()\n",
        "\n",
        "\n",
        "        indicators['SMA_20'] = ta.trend.SMAIndicator(close=close_prices, window=20).sma_indicator()\n",
        "        indicators['SMA_50'] = ta.trend.SMAIndicator(close=close_prices, window=50).sma_indicator()\n",
        "        indicators['EMA_12'] = ta.trend.EMAIndicator(close=close_prices, window=12).ema_indicator()\n",
        "        indicators['EMA_26'] = ta.trend.EMAIndicator(close=close_prices, window=26).ema_indicator()\n",
        "\n",
        "\n",
        "        bollinger = ta.volatility.BollingerBands(close=close_prices, window=20, window_dev=2)\n",
        "        indicators['BB_Upper'] = bollinger.bollinger_hband()\n",
        "        indicators['BB_Lower'] = bollinger.bollinger_lband()\n",
        "        indicators['BB_Middle'] = bollinger.bollinger_mavg()\n",
        "        indicators['BB_Width'] = (indicators['BB_Upper'] - indicators['BB_Lower']) / indicators['BB_Middle']\n",
        "\n",
        "\n",
        "        indicators['ATR'] = ta.volatility.AverageTrueRange(\n",
        "            high=high_prices, low=low_prices, close=close_prices, window=14\n",
        "        ).average_true_range()\n",
        "\n",
        "\n",
        "        stoch = ta.momentum.StochasticOscillator(high=high_prices, low=low_prices, close=close_prices, window=14)\n",
        "        indicators['Stoch_K'] = stoch.stoch()\n",
        "        indicators['Stoch_D'] = stoch.stoch_signal()\n",
        "\n",
        "\n",
        "        indicators['Volume'] = volume\n",
        "        indicators['Volume_SMA'] = ta.trend.SMAIndicator(close=volume, window=20).sma_indicator()\n",
        "        indicators['OBV'] = ta.volume.OnBalanceVolumeIndicator(close=close_prices, volume=volume).on_balance_volume()\n",
        "\n",
        "\n",
        "        indicators['Price_Change'] = close_prices.pct_change()\n",
        "        indicators['High_Low_Ratio'] = high_prices / low_prices\n",
        "        indicators['Close_Open_Ratio'] = close_prices / open_prices\n",
        "\n",
        "        indicators_df = pd.DataFrame(indicators, index=data_df.index)\n",
        "\n",
        "\n",
        "        indicators_df = indicators_df.ffill().bfill()\n",
        "\n",
        "        indicators_df = indicators_df.dropna()\n",
        "\n",
        "        return indicators_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error computing indicators for {ticker}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def build_lstm_model(input_shape, output_units):\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = LSTM(units=64, return_sequences=True)(inputs)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = LSTM(units=32, return_sequences=True)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = LSTM(units=16)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    outputs = Dense(output_units)(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def portfolio_return(weights, mu):\n",
        "    return np.dot(weights, mu)\n",
        "\n",
        "def portfolio_volatility(weights, Sigma):\n",
        "    return np.sqrt(np.dot(weights.T, np.dot(Sigma, weights)))\n",
        "\n",
        "def neg_sharpe_ratio(weights, mu, Sigma, risk_free_rate):\n",
        "    p_ret = portfolio_return(weights, mu)\n",
        "    p_vol = portfolio_volatility(weights, Sigma)\n",
        "    if p_vol < 1e-6:\n",
        "        return 1e10\n",
        "    return - (p_ret - risk_free_rate) / p_vol\n",
        "\n",
        "def objective_min_risk_contrib(weights, Sigma, N_STOCKS):\n",
        "\n",
        "    p_vol = portfolio_volatility(weights, Sigma)\n",
        "\n",
        "    if p_vol < 1e-10:\n",
        "        return 0\n",
        "    MCR = np.dot(Sigma, weights) / p_vol\n",
        "    RC = weights * MCR\n",
        "    target_RC = np.ones_like(weights) / N_STOCKS\n",
        "    return np.sum((RC - target_RC)**2)\n",
        "\n",
        "def diversification_penalty(weights, min_crypto=8, threshold=0.005):\n",
        "\n",
        "    meaningful_crypto = np.sum(weights > threshold)\n",
        "    if meaningful_crypto < min_crypto:\n",
        "        return 1000 * (min_crypto - meaningful_crypto)\n",
        "    return 0\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- 1. DATA ACQUISITION & FEATURE ENGINEERING ---\")\n",
        "\n",
        "\n",
        "crypto_data, successful_tickers = download_crypto_data(ALL_TICKERS, start_date, end_date)\n",
        "\n",
        "if len(successful_tickers) < 10:\n",
        "    print(\" Insufficient cryptocurrencies with valid data. Exiting.\")\n",
        "else:\n",
        "\n",
        "    print(\"\\nAligning data to common date range...\")\n",
        "    all_closes = pd.DataFrame()\n",
        "    all_indicators = {}\n",
        "\n",
        "\n",
        "    for ticker in successful_tickers:\n",
        "        all_closes[ticker] = crypto_data[ticker]['Close']\n",
        "\n",
        "\n",
        "        indicators_df = compute_technical_indicators_single(crypto_data[ticker], ticker)\n",
        "        if indicators_df is not None:\n",
        "            all_indicators[ticker] = indicators_df\n",
        "\n",
        "\n",
        "    common_dates = all_closes.index\n",
        "    for ticker in all_indicators.keys():\n",
        "        common_dates = common_dates.intersection(all_indicators[ticker].index)\n",
        "\n",
        "    if len(common_dates) < 100:\n",
        "        print(\" Insufficient common dates after alignment. Exiting.\")\n",
        "    else:\n",
        "        print(f\"Common date range: {common_dates.min()} to {common_dates.max()}\")\n",
        "        print(f\"Total trading days: {len(common_dates)}\")\n",
        "\n",
        "\n",
        "        all_closes_aligned = all_closes.loc[common_dates].dropna(axis=1)\n",
        "\n",
        "\n",
        "        final_tickers = all_closes_aligned.columns.tolist()\n",
        "\n",
        "\n",
        "        final_indicators = {\n",
        "            ticker: all_indicators[ticker].loc[common_dates]\n",
        "            for ticker in final_tickers if ticker in all_indicators\n",
        "        }\n",
        "\n",
        "\n",
        "        final_tickers = [t for t in final_tickers if t in final_indicators]\n",
        "        all_closes_aligned = all_closes_aligned[final_tickers]\n",
        "\n",
        "        print(f\"Final dataset: {all_closes_aligned.shape[1]} cryptocurrencies, {all_closes_aligned.shape[0]} trading days\")\n",
        "\n",
        "\n",
        "\n",
        "        print(\"\\n--- 2. K-MEANS CLUSTERING (Risk Filtering - FIXED) ---\")\n",
        "\n",
        "        daily_returns = all_closes_aligned.pct_change().dropna()\n",
        "\n",
        "        if daily_returns.empty:\n",
        "            print(\" No valid returns data. Exiting.\")\n",
        "        else:\n",
        "            annual_volatility = daily_returns.std() * np.sqrt(252)\n",
        "            volatility_df = pd.DataFrame(annual_volatility, columns=['Annual_Volatility']).dropna()\n",
        "\n",
        "            if volatility_df.empty:\n",
        "                print(\" No valid volatility data. Exiting.\")\n",
        "            else:\n",
        "                print(f\"Volatility range: {volatility_df['Annual_Volatility'].min():.3f} to {volatility_df['Annual_Volatility'].max():.3f}\")\n",
        "\n",
        "                volatility_matrix = volatility_df.values\n",
        "                scaler_risk = MinMaxScaler()\n",
        "                scaled_risk = scaler_risk.fit_transform(volatility_matrix)\n",
        "\n",
        "\n",
        "                K = min(4, len(volatility_df))\n",
        "\n",
        "\n",
        "                if K < MIN_CRYPTO_IN_PORTFOLIO:\n",
        "                     print(f\" Only {len(volatility_df)} assets available, which is less than MIN_CRYPTO_IN_PORTFOLIO ({MIN_CRYPTO_IN_PORTFOLIO}). Selecting all available assets.\")\n",
        "                     least_risk_tickers = volatility_df.index.tolist()\n",
        "                else:\n",
        "                    kmeans = KMeans(n_clusters=K, random_state=42, n_init='auto')\n",
        "                    clusters = kmeans.fit_predict(scaled_risk)\n",
        "                    volatility_df['Cluster'] = clusters\n",
        "\n",
        "                    cluster_centers = kmeans.cluster_centers_\n",
        "\n",
        "\n",
        "                    sorted_cluster_indices = np.argsort(cluster_centers.flatten())\n",
        "\n",
        "\n",
        "                    least_risk_tickers = []\n",
        "\n",
        "                    for cluster_id in sorted_cluster_indices:\n",
        "                        current_cluster_tickers = volatility_df[volatility_df['Cluster'] == cluster_id].index.tolist()\n",
        "                        least_risk_tickers.extend(current_cluster_tickers)\n",
        "\n",
        "                        if len(least_risk_tickers) >= MIN_CRYPTO_IN_PORTFOLIO:\n",
        "\n",
        "                            break\n",
        "\n",
        "\n",
        "                    least_risk_tickers = list(set(least_risk_tickers))\n",
        "\n",
        "\n",
        "                N_STOCKS = len(least_risk_tickers)\n",
        "\n",
        "                print(f\"Total available cryptocurrencies: {len(final_tickers)}\")\n",
        "                print(f\"Selected Low-Risk Cryptocurrencies for Optimization: {N_STOCKS}\")\n",
        "                print(f\"Low-Risk Cryptocurrencies: {least_risk_tickers}\")\n",
        "\n",
        "\n",
        "\n",
        "                if N_STOCKS < MIN_CRYPTO_IN_PORTFOLIO:\n",
        "                    print(f\" FINAL ERROR: Despite fix, selected assets ({N_STOCKS}) is less than required minimum ({MIN_CRYPTO_IN_PORTFOLIO}). This should only happen if total available assets < {MIN_CRYPTO_IN_PORTFOLIO}.\")\n",
        "                    print(\"Optimization will proceed with available assets, but diversification constraints might be impossible.\")\n",
        "\n",
        "\n",
        "\n",
        "                selected_tickers = least_risk_tickers\n",
        "                data_dl_close = all_closes_aligned[selected_tickers].copy()\n",
        "\n",
        "\n",
        "                final_indicators_selected = {\n",
        "                    ticker: final_indicators[ticker] for ticker in selected_tickers\n",
        "                }\n",
        "\n",
        "\n",
        "\n",
        "                print(\"\\n--- 3. DEEP LEARNING (LSTM) FOR PREDICTION WITH TECHNICAL INDICATORS ---\")\n",
        "\n",
        "\n",
        "                print(\"Preparing combined price and technical indicator data...\")\n",
        "\n",
        "                X_combined_list = []\n",
        "                y_combined_list = []\n",
        "                price_scalers = {}\n",
        "\n",
        "                for ticker in selected_tickers:\n",
        "                    price_data = data_dl_close[[ticker]].copy()\n",
        "                    indicators_data = final_indicators_selected[ticker]\n",
        "\n",
        "\n",
        "                    scaler_price = MinMaxScaler(feature_range=(0, 1))\n",
        "                    price_normalized = scaler_price.fit_transform(price_data)\n",
        "                    price_scalers[ticker] = scaler_price\n",
        "\n",
        "\n",
        "                    scaler_indicators = MinMaxScaler(feature_range=(0, 1))\n",
        "                    indicators_normalized = scaler_indicators.fit_transform(indicators_data)\n",
        "\n",
        "\n",
        "                    features_normalized = np.concatenate([price_normalized, indicators_normalized], axis=1)\n",
        "\n",
        "\n",
        "                    X_crypto, y_crypto = [], []\n",
        "                    for i in range(len(features_normalized) - LOOKBACK):\n",
        "                        X_crypto.append(features_normalized[i:(i + LOOKBACK)])\n",
        "\n",
        "                        y_crypto.append(price_normalized[i + LOOKBACK])\n",
        "\n",
        "                    X_combined_list.append(np.array(X_crypto))\n",
        "                    y_combined_list.append(np.array(y_crypto))\n",
        "\n",
        "\n",
        "\n",
        "                min_length = min([len(X) for X in X_combined_list])\n",
        "                X_aligned = [X[:min_length] for X in X_combined_list]\n",
        "                y_aligned = [y[:min_length] for y in y_combined_list]\n",
        "\n",
        "\n",
        "                X_combined = np.stack(X_aligned, axis=2)\n",
        "                y_combined = np.stack(y_aligned, axis=1).squeeze()\n",
        "\n",
        "\n",
        "                n_samples, lookback, n_features, n_assets = X_combined.shape\n",
        "                X_reshaped = X_combined.reshape(n_samples, lookback, n_features * n_assets)\n",
        "\n",
        "                print(f\"Combined training sequences: {X_reshaped.shape}\")\n",
        "                print(f\"Target shape: {y_combined.shape}\")\n",
        "\n",
        "                if len(X_reshaped) == 0:\n",
        "                    print(\" Insufficient data for sequence creation. Exiting.\")\n",
        "                else:\n",
        "                    TRAIN_SIZE = int(0.8 * len(X_reshaped))\n",
        "                    X_train = X_reshaped[:TRAIN_SIZE]\n",
        "                    y_train = y_combined[:TRAIN_SIZE]\n",
        "\n",
        "                    print(f\"Training sequences: {X_train.shape}\")\n",
        "                    print(f\"Features per sequence: {X_train.shape[2]}\")\n",
        "\n",
        "\n",
        "                    model = build_lstm_model(input_shape=(LOOKBACK, X_train.shape[2]), output_units=N_STOCKS)\n",
        "\n",
        "                    print(\"Starting LSTM model training with technical indicators\")\n",
        "                    history = model.fit(\n",
        "                        X_train,\n",
        "                        y_train,\n",
        "                        epochs=EPOCHS,\n",
        "                        batch_size=min(BATCH_SIZE, len(X_train)),\n",
        "                        verbose=1,\n",
        "                        validation_split=0.1\n",
        "                    )\n",
        "                    print(\"Model training complete.\")\n",
        "\n",
        "\n",
        "                    last_lookback_data = X_reshaped[-1:].reshape(1, LOOKBACK, X_reshaped.shape[2])\n",
        "                    predicted_scaled_prices = model.predict(last_lookback_data, verbose=0)\n",
        "\n",
        "\n",
        "                    predicted_prices_list = []\n",
        "                    for i, ticker in enumerate(selected_tickers):\n",
        "                        scaler_price = price_scalers[ticker]\n",
        "\n",
        "\n",
        "                        pred_scaled = predicted_scaled_prices[0, i].reshape(-1, 1)\n",
        "                        pred_price = scaler_price.inverse_transform(pred_scaled)[0, 0]\n",
        "                        predicted_prices_list.append(pred_price)\n",
        "\n",
        "                    predicted_prices_series = pd.Series(predicted_prices_list, index=selected_tickers)\n",
        "                    last_close_prices = data_dl_close.iloc[-1]\n",
        "                    mu_predictions = (predicted_prices_series / last_close_prices) - 1\n",
        "                    mu_predictions.name = 'Expected_Return_LSTM'\n",
        "\n",
        "                    print(\"\\nPredicted returns:\")\n",
        "                    print(mu_predictions.round(4))\n",
        "\n",
        "\n",
        "\n",
        "                    print(\"\\n--- 4. PORTFOLIO OPTIMIZATION (With STRICT Diversification) ---\")\n",
        "\n",
        "\n",
        "                    returns = data_dl_close.pct_change().dropna()\n",
        "                    returns = returns[mu_predictions.index]\n",
        "\n",
        "                    if returns.empty:\n",
        "                        print(\" No valid returns data for optimization. Exiting.\")\n",
        "                    else:\n",
        "                        Sigma = returns.cov() * 252\n",
        "                        mu_array = mu_predictions.values\n",
        "                        Sigma_array = Sigma.values\n",
        "\n",
        "                        print(f\"Covariance matrix shape: {Sigma_array.shape}\")\n",
        "\n",
        "\n",
        "                        constraints = [\n",
        "                            {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
        "                        ]\n",
        "\n",
        "\n",
        "                        bounds = tuple((MIN_WEIGHT_PER_CRYPTO, MAX_WEIGHT_PER_CRYPTO) for asset in range(N_STOCKS))\n",
        "                        initial_weights = np.array([1/N_STOCKS] * N_STOCKS)\n",
        "\n",
        "\n",
        "                        min_possible_sum = MIN_WEIGHT_PER_CRYPTO * N_STOCKS\n",
        "                        max_possible_sum = MAX_WEIGHT_PER_CRYPTO * N_STOCKS\n",
        "\n",
        "                        if max_possible_sum < 1.0:\n",
        "                            print(f\" IMPOSSIBLE CONSTRAINT: Max weight (15%) * {N_STOCKS} assets = {max_possible_sum*100}%. Cannot sum to 100%. Adjust MAX_WEIGHT_PER_CRYPTO.\")\n",
        "                        elif min_possible_sum > 1.0:\n",
        "                            print(f\" IMPOSSIBLE CONSTRAINT: Min weight (1%) * {N_STOCKS} assets = {min_possible_sum*100}%. Cannot sum to 100%. Adjust MIN_WEIGHT_PER_CRYPTO.\")\n",
        "                        else:\n",
        "                            print(\"Running optimization strategies with strict diversification\")\n",
        "\n",
        "\n",
        "                            def neg_sharpe_ratio_diversified(weights, mu, Sigma, risk_free_rate):\n",
        "                                base_sharpe = neg_sharpe_ratio(weights, mu, Sigma, risk_free_rate)\n",
        "                                div_penalty = diversification_penalty(weights, MIN_CRYPTO_IN_PORTFOLIO)\n",
        "                                return base_sharpe + div_penalty\n",
        "\n",
        "                            def portfolio_volatility_diversified(weights, Sigma):\n",
        "                                base_vol = portfolio_volatility(weights, Sigma)\n",
        "                                div_penalty = diversification_penalty(weights, MIN_CRYPTO_IN_PORTFOLIO)\n",
        "                                return base_vol + div_penalty\n",
        "\n",
        "                            def objective_min_risk_contrib_diversified(weights, Sigma, N_STOCKS):\n",
        "                                base_obj = objective_min_risk_contrib(weights, Sigma, N_STOCKS)\n",
        "                                div_penalty = diversification_penalty(weights, MIN_CRYPTO_IN_PORTFOLIO)\n",
        "                                return base_obj + div_penalty\n",
        "\n",
        "\n",
        "                            strategies_weights = {}\n",
        "\n",
        "                            try:\n",
        "\n",
        "                                opt_mvor = minimize(neg_sharpe_ratio_diversified, initial_weights,\n",
        "                                                    args=(mu_array, Sigma_array, RISK_FREE_RATE),\n",
        "                                                    method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "                                if opt_mvor.success:\n",
        "                                    strategies_weights['MVOR (Max Sharpe)'] = opt_mvor.x\n",
        "                                else:\n",
        "                                    print(f\"  MVOR optimization failed: {opt_mvor.message}\")\n",
        "\n",
        "\n",
        "                                opt_gmv = minimize(portfolio_volatility_diversified, initial_weights,\n",
        "                                                   args=(Sigma_array,),\n",
        "                                                   method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "                                if opt_gmv.success:\n",
        "                                    strategies_weights['GMV (Min Volatility)'] = opt_gmv.x\n",
        "                                else:\n",
        "                                    print(f\"  GMV optimization failed: {opt_gmv.message}\")\n",
        "\n",
        "\n",
        "                                opt_erc = minimize(objective_min_risk_contrib_diversified, initial_weights,\n",
        "                                                   args=(Sigma_array, N_STOCKS),\n",
        "                                                   method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "                                if opt_erc.success:\n",
        "                                    strategies_weights['ERC (Equal Risk Contrib.)'] = opt_erc.x\n",
        "                                else:\n",
        "                                    print(f\"  ERC optimization failed: {opt_erc.message}\")\n",
        "\n",
        "                            except Exception as e:\n",
        "                                print(f\" Optimization error: {str(e)}\")\n",
        "\n",
        "                            if not strategies_weights:\n",
        "                                print(\" All optimizations failed. Exiting.\")\n",
        "                            else:\n",
        "\n",
        "                                def analyze_portfolio_diversification(weights, tickers, threshold=0.005):\n",
        "\n",
        "                                    weights_series = pd.Series(weights, index=tickers)\n",
        "                                    meaningful_allocation = weights_series[weights_series > threshold]\n",
        "                                    n_crypto = len(meaningful_allocation)\n",
        "\n",
        "                                    top_weight = weights_series.max()\n",
        "                                    top_2_weights = weights_series.nlargest(2).sum()\n",
        "                                    top_5_weights = weights_series.nlargest(5).sum()\n",
        "                                    herfindahl = np.sum(weights_series ** 2)\n",
        "\n",
        "                                    return {\n",
        "                                        'n_crypto_meaningful': n_crypto,\n",
        "                                        'max_weight': top_weight,\n",
        "                                        'top_2_concentration': top_2_weights,\n",
        "                                        'top_5_concentration': top_5_weights,\n",
        "                                        'herfindahl_index': herfindahl\n",
        "                                    }\n",
        "\n",
        "                                def get_portfolio_metrics(weights, mu, Sigma, rf):\n",
        "                                    weights = np.array(weights)\n",
        "                                    p_ret = portfolio_return(weights, mu)\n",
        "                                    p_vol = portfolio_volatility(weights, Sigma)\n",
        "                                    p_sharpe = (p_ret - rf) / p_vol if p_vol > 1e-6 else 0\n",
        "                                    return p_ret, p_vol, p_sharpe\n",
        "\n",
        "\n",
        "                                performance_metrics = {}\n",
        "                                final_weights = {}\n",
        "                                diversification_metrics = {}\n",
        "\n",
        "                                for name, w_array in strategies_weights.items():\n",
        "                                    w_final = np.array(w_array)\n",
        "                                    p_ret, p_vol, p_sharpe = get_portfolio_metrics(w_final, mu_array, Sigma_array, RISK_FREE_RATE)\n",
        "\n",
        "                                    performance_metrics[name] = (p_ret, p_vol, p_sharpe)\n",
        "                                    final_weights[name] = pd.Series(w_final, index=selected_tickers)\n",
        "                                    diversification_metrics[name] = analyze_portfolio_diversification(w_final, selected_tickers)\n",
        "\n",
        "\n",
        "\n",
        "                                print(\"\\n--- 5. RESULTS AND DIVERSIFICATION ANALYSIS ---\")\n",
        "\n",
        "\n",
        "                                metrics_df = pd.DataFrame(performance_metrics,\n",
        "                                                         index=['Expected Annual Return', 'Annual Volatility', 'Sharpe Ratio']).T\n",
        "\n",
        "                                print(\"\\n### 5.1 Portfolio Performance Comparison ###\")\n",
        "                                print(metrics_df.round(4).to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "                                print(f\"\\n### 5.2 Diversification Analysis ###\")\n",
        "                                div_df = pd.DataFrame(diversification_metrics).T\n",
        "                                print(div_df.round(4).to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "                                full_weights_df = pd.DataFrame(final_weights).T\n",
        "\n",
        "                                print(\"\\n### 5.3 Portfolio Weights ###\")\n",
        "\n",
        "                                print(full_weights_df.map(lambda x: f\"{x:.2%}\").to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "\n",
        "                                print(f\"\\n### 5.4 Concentration Warnings ###\")\n",
        "                                for strategy, div_metrics in diversification_metrics.items():\n",
        "                                    warnings = []\n",
        "                                    if div_metrics['max_weight'] > 0.20:\n",
        "                                        warnings.append(f\"Single crypto concentration: {div_metrics['max_weight']:.1%}\")\n",
        "                                    if div_metrics['top_2_concentration'] > 0.35:\n",
        "                                        warnings.append(f\"Top 2 concentration: {div_metrics['top_2_concentration']:.1%}\")\n",
        "                                    if div_metrics['n_crypto_meaningful'] < MIN_CRYPTO_IN_PORTFOLIO:\n",
        "                                        warnings.append(f\"Only {div_metrics['n_crypto_meaningful']} cryptos with meaningful weights\")\n",
        "\n",
        "                                    if warnings:\n",
        "                                        print(f\"{strategy}: {' | '.join(warnings)}\")\n",
        "                                    else:\n",
        "                                        print(f\"{strategy}: Well diversified \")\n",
        "\n",
        "                                print(f\"\\nDiversification Constraints Applied:\")\n",
        "                                print(f\"- Maximum weight per crypto: {MAX_WEIGHT_PER_CRYPTO:.1%}\")\n",
        "                                print(f\"- Minimum weight per crypto: {MIN_WEIGHT_PER_CRYPTO:.1%}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAWNwGfT4Lct",
        "outputId": "ced6efae-65d6-4b37-817f-64d837f2d211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. DATA ACQUISITION & FEATURE ENGINEERING ---\n",
            "Downloading data for 18 cryptocurrencies...\n",
            "    Successfully downloaded BTC-USD\n",
            "    Successfully downloaded ETH-USD\n",
            "    Successfully downloaded BNB-USD\n",
            "    Successfully downloaded SOL-USD\n",
            "    Successfully downloaded XRP-USD\n",
            "    Successfully downloaded ADA-USD\n",
            "    Successfully downloaded AVAX-USD\n",
            "    Successfully downloaded DOGE-USD\n",
            "    Successfully downloaded DOT-USD\n",
            "    Successfully downloaded TRX-USD\n",
            "    Successfully downloaded LINK-USD\n",
            "    Successfully downloaded MATIC-USD\n",
            "    Successfully downloaded LTC-USD\n",
            "    Successfully downloaded BCH-USD\n",
            "    Successfully downloaded ATOM-USD\n",
            "    Successfully downloaded UNI-USD\n",
            "    Successfully downloaded XLM-USD\n",
            "    Successfully downloaded ETC-USD\n",
            "Successfully downloaded 18 out of 18 cryptocurrencies\n",
            "\n",
            "Aligning data to common date range...\n",
            "Common date range: 2020-09-22 00:00:00 to 2024-12-30 00:00:00\n",
            "Total trading days: 1561\n",
            "Final dataset: 18 cryptocurrencies, 1561 trading days\n",
            "\n",
            "--- 2. K-MEANS CLUSTERING (Risk Filtering - FIXED) ---\n",
            "Volatility range: 0.513 to 6326.136\n",
            " Only 18 assets available, which is less than MIN_CRYPTO_IN_PORTFOLIO (8). Selecting all available assets.\n",
            "Total available cryptocurrencies: 18\n",
            "Selected Low-Risk Cryptocurrencies for Optimization: 18\n",
            "Low-Risk Cryptocurrencies: ['BTC-USD', 'ETH-USD', 'BNB-USD', 'SOL-USD', 'XRP-USD', 'ADA-USD', 'AVAX-USD', 'DOGE-USD', 'DOT-USD', 'TRX-USD', 'LINK-USD', 'MATIC-USD', 'LTC-USD', 'BCH-USD', 'ATOM-USD', 'UNI-USD', 'XLM-USD', 'ETC-USD']\n",
            "\n",
            "--- 3. DEEP LEARNING (LSTM) FOR PREDICTION WITH TECHNICAL INDICATORS ---\n",
            "Preparing combined price and technical indicator data...\n",
            "Combined training sequences: (1501, 60, 396)\n",
            "Target shape: (1501, 18)\n",
            "Training sequences: (1200, 60, 396)\n",
            "Features per sequence: 396\n",
            "Starting LSTM model training with technical indicators\n",
            "Epoch 1/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - loss: 0.0818 - mae: 0.2074 - val_loss: 0.0139 - val_mae: 0.0879\n",
            "Epoch 2/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0406 - mae: 0.1370 - val_loss: 0.0073 - val_mae: 0.0630\n",
            "Epoch 3/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - loss: 0.0229 - mae: 0.1030 - val_loss: 0.0057 - val_mae: 0.0601\n",
            "Epoch 4/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0192 - mae: 0.0950 - val_loss: 0.0057 - val_mae: 0.0558\n",
            "Epoch 5/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0155 - mae: 0.0848 - val_loss: 0.0046 - val_mae: 0.0495\n",
            "Epoch 6/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - loss: 0.0141 - mae: 0.0804 - val_loss: 0.0049 - val_mae: 0.0536\n",
            "Epoch 7/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0110 - mae: 0.0721 - val_loss: 0.0051 - val_mae: 0.0549\n",
            "Epoch 8/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0112 - mae: 0.0715 - val_loss: 0.0045 - val_mae: 0.0496\n",
            "Epoch 9/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0096 - mae: 0.0660 - val_loss: 0.0052 - val_mae: 0.0576\n",
            "Epoch 10/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.0088 - mae: 0.0629 - val_loss: 0.0053 - val_mae: 0.0543\n",
            "Model training complete.\n",
            "\n",
            "Predicted returns:\n",
            "BTC-USD     -0.3902\n",
            "ETH-USD      0.1170\n",
            "BNB-USD     -0.3272\n",
            "SOL-USD     -0.2779\n",
            "XRP-USD     -0.5021\n",
            "ADA-USD      0.7155\n",
            "AVAX-USD     0.5204\n",
            "DOGE-USD    -0.2987\n",
            "DOT-USD      2.7150\n",
            "TRX-USD     -0.6495\n",
            "LINK-USD     0.1590\n",
            "MATIC-USD    2.0288\n",
            "LTC-USD      0.3968\n",
            "BCH-USD      0.4245\n",
            "ATOM-USD     2.5410\n",
            "UNI-USD     -3.4776\n",
            "XLM-USD     -0.0889\n",
            "ETC-USD      0.7489\n",
            "Name: Expected_Return_LSTM, dtype: float64\n",
            "\n",
            "--- 4. PORTFOLIO OPTIMIZATION (With STRICT Diversification) ---\n",
            "Covariance matrix shape: (18, 18)\n",
            "Running optimization strategies with strict diversification\n",
            "\n",
            "--- 5. RESULTS AND DIVERSIFICATION ANALYSIS ---\n",
            "\n",
            "### 5.1 Portfolio Performance Comparison ###\n",
            "|                           | Expected Annual Return   | Annual Volatility   | Sharpe Ratio   |\n",
            "|:--------------------------|:-------------------------|:--------------------|:---------------|\n",
            "| MVOR (Max Sharpe)         | 1.3309                   | 63.2722             | 0.0207         |\n",
            "| GMV (Min Volatility)      | 0.3516                   | 63.2673             | 0.0052         |\n",
            "| ERC (Equal Risk Contrib.) | 0.2419                   | 351.456             | 0.0006         |\n",
            "\n",
            "### 5.2 Diversification Analysis ###\n",
            "|                           | n_crypto_meaningful   | max_weight   | top_2_concentration   | top_5_concentration   | herfindahl_index   |\n",
            "|:--------------------------|:----------------------|:-------------|:----------------------|:----------------------|:-------------------|\n",
            "| MVOR (Max Sharpe)         | 18                    | 0.15         | 0.3                   | 0.75                  | 0.1306             |\n",
            "| GMV (Min Volatility)      | 18                    | 0.0793       | 0.155                 | 0.3658                | 0.0605             |\n",
            "| ERC (Equal Risk Contrib.) | 18                    | 0.0556       | 0.1111                | 0.2778                | 0.0556             |\n",
            "\n",
            "### 5.3 Portfolio Weights ###\n",
            "|                           | BTC-USD   | ETH-USD   | BNB-USD   | SOL-USD   | XRP-USD   | ADA-USD   | AVAX-USD   | DOGE-USD   | DOT-USD   | TRX-USD   | LINK-USD   | MATIC-USD   | LTC-USD   | BCH-USD   | ATOM-USD   | UNI-USD   | XLM-USD   | ETC-USD   |\n",
            "|:--------------------------|:----------|:----------|:----------|:----------|:----------|:----------|:-----------|:-----------|:----------|:----------|:-----------|:------------|:----------|:----------|:-----------|:----------|:----------|:----------|\n",
            "| MVOR (Max Sharpe)         | 1.00%     | 1.00%     | 1.00%     | 1.00%     | 1.00%     | 15.00%    | 13.00%     | 1.00%      | 15.00%    | 1.00%     | 1.00%      | 15.00%      | 1.00%     | 1.00%     | 15.00%     | 1.00%     | 1.00%     | 15.00%    |\n",
            "| GMV (Min Volatility)      | 6.60%     | 5.84%     | 6.87%     | 6.98%     | 4.34%     | 4.59%     | 3.86%      | 7.23%      | 7.57%     | 7.93%     | 4.81%      | 4.42%       | 6.13%     | 6.33%     | 3.97%      | 1.00%     | 6.21%     | 5.32%     |\n",
            "| ERC (Equal Risk Contrib.) | 5.56%     | 5.56%     | 5.56%     | 5.56%     | 5.56%     | 5.56%     | 5.56%      | 5.56%      | 5.56%     | 5.56%     | 5.56%      | 5.56%       | 5.56%     | 5.56%     | 5.56%      | 5.56%     | 5.56%     | 5.56%     |\n",
            "\n",
            "### 5.4 Concentration Warnings ###\n",
            "MVOR (Max Sharpe): Well diversified \n",
            "GMV (Min Volatility): Well diversified \n",
            "ERC (Equal Risk Contrib.): Well diversified \n",
            "\n",
            "Diversification Constraints Applied:\n",
            "- Maximum weight per crypto: 15.0%\n",
            "- Minimum weight per crypto: 1.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Interpreting the Results**\n",
        "\n",
        "* **Portfolio Constraints:**\n",
        "\n",
        "All optimization runs are subjected to **strict diversification constraints** (Minimum weight of $1.0\\%$ and Maximum weight of $15.0\\%$ per asset), ensuring a practical, balanced portfolio, regardless of the optimization strategy.\n",
        "\n",
        "* **Sharpe Ratio Context:** The low resultant Sharpe Ratios are acknowledged and expected.\n",
        "\n",
        "This outcome is a direct consequence of combining the LSTM's volatile short-term predictions with a risk metric that is deliberately miscalculated for the crypto market (via the 252-day stock-like simulation).\n",
        "\n",
        "The performance numbers reflect the difficulty of achieving high risk-adjusted returns under this simulation environment, but this does not detract from the primary goal of **methodological comparison**.\n",
        "\n",
        "**Warning**:\n",
        "\n",
        "This notebook is not a financial advisor."
      ],
      "metadata": {
        "id": "0rUUb1XU8jF8"
      }
    }
  ]
}